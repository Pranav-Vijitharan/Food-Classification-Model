{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sesjZ0KiDdz"
      },
      "source": [
        "<table class=\"table table-bordered\">\n",
        "    <tr>\n",
        "        <th style=\"text-align:center; vertical-align: middle; width:50%\"><img src='https://www.np.edu.sg/images/default-source/default-album/img-logo.png'\"></th>\n",
        "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 1 - Food Classification Model (Individual)</h2><h3>AY2023/24 Semester</h3></th>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT93Bu-A1DgT",
        "outputId": "d30f7be8-dee0-4987-ce4d-eaf2dcfccd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBL45hPaiDd5"
      },
      "outputs": [],
      "source": [
        "# Import the Required Packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import keras_tuner as kt\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu1b_FOniDd7"
      },
      "source": [
        "## Step 1: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvOHtP9CiDd7",
        "outputId": "aecf7ba0-cabc-4f9f-bf6d-7e74317116b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'Ngee Ann Poly'  'Udemy Courses'\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/\"\n",
        "base_dir = \"/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Images\"\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8PR8SswiDd8"
      },
      "source": [
        "## Step 2:  Develop the Image Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T50DxKvO17oc",
        "outputId": "cf65044f-6894-411a-ef08-3cac83617bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n",
            "Found 500 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "img_size = 224\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=50,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=50,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=50,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wiqs2lI2DE6"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    img_size = 224\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Resizing(img_size, img_size, crop_to_aspect_ratio=True, input_shape=(None, None, 3)))\n",
        "\n",
        "    # Define hyperparameters to tune\n",
        "    hp_filters = hp.Int('filters', min_value=32, max_value=512, step=32)\n",
        "    hp_dense_units = hp.Int('units', min_value=1024, max_value=8192, step=1024)\n",
        "    hp_conv_layers = hp.Int('conv_layers', min_value=2, max_value=5)\n",
        "    hp_pooling = hp.Choice('pooling', values=['max', 'avg'])\n",
        "    hp_kernel_size = hp.Choice('kernel_size', values=[3, 5, 7])  # Different kernel sizes to try\n",
        "\n",
        "    # Add convolutional layers based on the hyperparameters\n",
        "    for _ in range(hp_conv_layers):\n",
        "        model.add(layers.Conv2D(hp_filters, (hp_kernel_size, hp_kernel_size), activation='relu', padding='same'))\n",
        "        if hp_pooling == 'max':\n",
        "            model.add(layers.MaxPooling2D((2, 2)))\n",
        "        else:\n",
        "            model.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "\n",
        "    # Add dense layers based on the hyperparameter\n",
        "    model.add(layers.Dense(hp_dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optimizers.Adam(learning_rate=0.0005),\n",
        "        metrics=['acc']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxi50SKGM2kR"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf'\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    monitor='val_acc',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0InJfvQS4NJy",
        "outputId": "cf5d0074-11e7-4b50-b10a-bc16390190b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "256               |256               |filters\n",
            "6144              |6144              |units\n",
            "3                 |3                 |conv_layers\n",
            "avg               |avg               |pooling\n",
            "5                 |5                 |kernel_size\n",
            "\n",
            "Epoch 1/50\n",
            "150/150 [==============================] - ETA: 0s - loss: 2.2491 - acc: 0.1387 \n",
            "Epoch 1: val_acc improved from -inf to 0.16050, saving model to /content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf\n",
            "150/150 [==============================] - 5467s 36s/step - loss: 2.2491 - acc: 0.1387 - val_loss: 2.2091 - val_acc: 0.1605\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - ETA: 0s - loss: 2.2118 - acc: 0.1616 \n",
            "Epoch 2: val_acc improved from 0.16050 to 0.16750, saving model to /content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf\n",
            "150/150 [==============================] - 5453s 36s/step - loss: 2.2118 - acc: 0.1616 - val_loss: 2.2039 - val_acc: 0.1675\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - ETA: 0s - loss: 2.1697 - acc: 0.1861 \n",
            "Epoch 3: val_acc improved from 0.16750 to 0.24750, saving model to /content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf\n",
            "150/150 [==============================] - 5454s 36s/step - loss: 2.1697 - acc: 0.1861 - val_loss: 2.0902 - val_acc: 0.2475\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - ETA: 0s - loss: 2.0426 - acc: 0.2509 \n",
            "Epoch 4: val_acc improved from 0.24750 to 0.29900, saving model to /content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf\n",
            "150/150 [==============================] - 5455s 36s/step - loss: 2.0426 - acc: 0.2509 - val_loss: 1.9613 - val_acc: 0.2990\n",
            "Epoch 5/50\n",
            " 99/150 [==================>...........] - ETA: 28:38 - loss: 1.9420 - acc: 0.2901"
          ]
        }
      ],
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=30,\n",
        "    directory='/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models',\n",
        "    project_name='Architecture Trials'\n",
        ")\n",
        "\n",
        "train_generator.reset()\n",
        "validation_generator.reset()\n",
        "test_generator.reset()\n",
        "\n",
        "tuner.search(train_generator, validation_data=validation_generator, epochs=50, steps_per_epoch=150, validation_steps=40, callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmsM7tBuEy19"
      },
      "outputs": [],
      "source": [
        "model_4 = tuner.get_best_models(num_models = 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unK4o_Z1FLGh"
      },
      "outputs": [],
      "source": [
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-qsVl8BiDd9"
      },
      "outputs": [],
      "source": [
        "model_4.save('/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2AIyYl3iDeA"
      },
      "source": [
        "## Step 3 – Evaluate the Developed Models using Testing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdnnl_0giDeA"
      },
      "outputs": [],
      "source": [
        "model_4 = keras.models.load_model('/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Saved Models/model_4.tf')\n",
        "\n",
        "evaluation_results = model_4.evaluate(test_generator, steps=len(test_generator))\n",
        "\n",
        "print(\"Test Loss:\", evaluation_results[0])\n",
        "print(\"Test Accuracy:\", evaluation_results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ici5cF8OejN1"
      },
      "outputs": [],
      "source": [
        "predictions = model_4.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true labels from the test data generator\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Create the classification report\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=test_generator.class_indices.keys())\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmMJQxKj-BvU"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rs7htYPiDeH"
      },
      "source": [
        "## Step 4  – Use the best model to make prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKRfb5HPiDeI"
      },
      "outputs": [],
      "source": [
        "# Load the food list (in alphabetical order)\n",
        "with open('/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/18.txt', 'r') as f: # the .txt file which contains a list of food assigned to you\n",
        "    x = f.readlines()\n",
        "food_list =[]\n",
        "for item in x:\n",
        "    food_list.append(item.strip('\\n'))\n",
        "food_list = sorted(food_list) # food_list needs to be sorted alphabetically before feed into prediction() function\n",
        "print(food_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpDoGUkaiDeI"
      },
      "outputs": [],
      "source": [
        "# Define some related functions for image process and model prediction\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "def image_process(img):\n",
        "    image = load_img(img, target_size =(img_size, img_size))\n",
        "    image_array = img_to_array(image)/255\n",
        "    return image_array\n",
        "\n",
        "import pandas as pd\n",
        "def prediction(model, img_array, items_l):\n",
        "    prob = model.predict(img_array.reshape(1,img_size,img_size,3))\n",
        "    pro_df = pd.DataFrame(prob, columns = items_l)\n",
        "    result = items_l[np.argmax(prob)]\n",
        "    return pro_df, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTJlJyICfGF8"
      },
      "outputs": [],
      "source": [
        "online_images_dir = '/content/drive/My Drive/Ngee Ann Poly/Deep Learning/ASG1/Online Images'\n",
        "image_files = os.listdir(online_images_dir)\n",
        "\n",
        "for image_file in image_files:\n",
        "    img_path = os.path.join(online_images_dir, image_file)\n",
        "    plt.imshow(plt.imread(img_path))\n",
        "    plt.show()\n",
        "\n",
        "    img_array = image_process(img_path)\n",
        "    prob_df, result = prediction(model_4, img_array, food_list)\n",
        "\n",
        "    print(f'\\nImage: {image_file}')\n",
        "    print('The prediction is:', result, '\\n\\n', prob_df)\n",
        "    print('-' * 40)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}